{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\hp\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hugging Face's Transformers : facebook/bart-large-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3e325fd1c741139a5c9ae25d930b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--facebook--bart-large-cnn. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cb99c8c78343cdad00e7398032f457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696ab4e1116e4e1bb2ce9c4320831c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb26b42e9ac64b57a97a18473734a9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dd4a3c76fa470eb545d261c8a7fb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad110b46eda744c0a552812824adb8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample long text\n",
    "text = \"\"\"\n",
    "Quantum computing has the potential to revolutionize fields like cryptography, optimization, \n",
    "and materials science. Unlike classical computers, which use bits as the smallest unit of data, \n",
    "quantum computers use qubits, which can exist in superposition states. This property enables \n",
    "quantum computers to perform certain calculations exponentially faster than their classical \n",
    "counterparts. However, challenges like error rates and qubit stability must be addressed for \n",
    "practical large-scale quantum computing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary\n",
    "summary = summarizer(text, max_length=50, min_length=20, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Quantum computing has the potential to revolutionize fields like cryptography, optimization, and materials science. Unlike classical computers, which use bits as the smallest unit of data, quantum computers use qubits.'}]\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing has the potential to revolutionize fields like cryptography, optimization, and materials science. Unlike classical computers, which use bits as the smallest unit of data, quantum computers use qubits.\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"\n",
    "SC grants relief from arrest to Allahbadia, with conditions. ...\n",
    "BJP slams Cong-led Telangana govt's Ramzan move, its AP ally issues same order. ...\n",
    "'I'm disgusted, but… ...\n",
    "'From biryani to kadak chai': Prez Murmu on India-Qatar ties amid Amir's visit. ...\n",
    "Here's where Tesla might set up its first showrooms in India.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary\n",
    "summary2 = summarizer(text2, max_length=50, min_length=20, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"BJP slams Cong-led Telangana govt's Ramzan move. SC grants relief from arrest to Allahbadia, with conditions.\"}]\n"
     ]
    }
   ],
   "source": [
    "print(summary2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hugging Face's Transformers : google/pegasus-xsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25abab05787d422d952ca4d972642d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--google--pegasus-xsum. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e877a2542a4442a9fc93e5102206b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0caeeff75c324e9fb5d44d4205414a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd3288ec0d04643acfea00912caf3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47b3b95e98940759beee6c0f250f907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70c522b9a27439491f8ac15af01b4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebe91b75a334d12b1640dcb5ac5bb0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "pegasus_summarizer = pipeline(\"summarization\", model=\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample long text\n",
    "text1 = \"\"\"\n",
    "Quantum computing has the potential to revolutionize fields like cryptography, optimization, \n",
    "and materials science. Unlike classical computers, which use bits as the smallest unit of data, \n",
    "quantum computers use qubits, which can exist in superposition states. This property enables \n",
    "quantum computers to perform certain calculations exponentially faster than their classical \n",
    "counterparts. However, challenges like error rates and qubit stability must be addressed for \n",
    "practical large-scale quantum computing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"Researchers at the Massachusetts Institute of Technology (MIT) have developed the world's first quantum computer.\"}]\n"
     ]
    }
   ],
   "source": [
    "pegasus_summary = pegasus_summarizer(text1, max_length=50, min_length=20, do_sample=False)\n",
    "print(pegasus_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"\n",
    "SC grants relief from arrest to Allahbadia, with conditions. ...\n",
    "BJP slams Cong-led Telangana govt's Ramzan move, its AP ally issues same order. ...\n",
    "'I'm disgusted, but… ...\n",
    "'From biryani to kadak chai': Prez Murmu on India-Qatar ties amid Amir's visit. ...\n",
    "Here's where Tesla might set up its first showrooms in India.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \"Here's a round-up of some of the quirkier snippets from the news in India this week:\"}]\n"
     ]
    }
   ],
   "source": [
    "pegasus_summary = pegasus_summarizer(text2, max_length=50, min_length=20, do_sample=False)\n",
    "print(pegasus_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Library : sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 97.3/97.3 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting breadability>=0.1.20\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sumy) (2.28.1)\n",
      "Requirement already satisfied: nltk>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sumy) (3.7)\n",
      "Collecting pycountry>=18.2.23\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: docopt<0.7,>=0.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sumy) (0.6.2)\n",
      "Requirement already satisfied: chardet in c:\\users\\hp\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
      "Requirement already satisfied: lxml>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (2022.7.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm->nltk>=3.0.2->sumy) (0.4.6)\n",
      "Building wheels for collected packages: breadability\n",
      "  Building wheel for breadability (setup.py): started\n",
      "  Building wheel for breadability (setup.py): finished with status 'done'\n",
      "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21695 sha256=ade92cf1f8d1b3bd0f3a911d5bfc3a77de313fd6cb8bf8c1d722f05abc6ff06b\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\ba\\9f\\70\\7795228568b81b57a8932755938da9fb1f291b0576752604aa\n",
      "Successfully built breadability\n",
      "Installing collected packages: pycountry, breadability, sumy\n",
      "Successfully installed breadability-0.1.20 pycountry-24.6.1 sumy-0.11.0\n"
     ]
    }
   ],
   "source": [
    "! pip install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractive_summary(text, num_sentences=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = LexRankSummarizer()\n",
    "    summary = summarizer(parser.document, num_sentences)\n",
    "    return \" \".join(str(sentence) for sentence in summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample long text\n",
    "text1 = \"\"\"\n",
    "Quantum computing has the potential to revolutionize fields like cryptography, optimization, \n",
    "and materials science. Unlike classical computers, which use bits as the smallest unit of data, \n",
    "quantum computers use qubits, which can exist in superposition states. This property enables \n",
    "quantum computers to perform certain calculations exponentially faster than their classical \n",
    "counterparts. However, challenges like error rates and qubit stability must be addressed for \n",
    "practical large-scale quantum computing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing has the potential to revolutionize fields like cryptography, optimization, and materials science. Unlike classical computers, which use bits as the smallest unit of data, quantum computers use qubits, which can exist in superposition states. This property enables quantum computers to perform certain calculations exponentially faster than their classical counterparts.\n"
     ]
    }
   ],
   "source": [
    "print(extractive_summary(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"\n",
    "SC grants relief from arrest to Allahbadia, with conditions. ...\n",
    "BJP slams Cong-led Telangana govt's Ramzan move, its AP ally issues same order. ...\n",
    "'I'm disgusted, but… ...\n",
    "'From biryani to kadak chai': Prez Murmu on India-Qatar ties amid Amir's visit. ...\n",
    "Here's where Tesla might set up its first showrooms in India.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC grants relief from arrest to Allahbadia, with conditions. ... BJP slams Cong-led Telangana govt's Ramzan move, its AP ally issues same order. ... 'I'm disgusted, but… ... 'From biryani to kadak chai': Prez Murmu on India-Qatar ties amid Amir's visit.\n"
     ]
    }
   ],
   "source": [
    "print(extractive_summary(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.47.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-win_amd64.whl (991 kB)\n",
      "     -------------------------------------- 991.5/991.5 kB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers sentencepiece torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfa3cb82d0f4bc084885f51ccb5fa31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--allenai--PRIMERA. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc0d03469674f2982f259eca2471a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e115a9ac8d534e59b44a113ff275e45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f763b2c96354c94bc2dabd07f5bdae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff43f1209a4416abd805cb438c6f88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/20.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412dda8fef374626918df6cdf2125f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/283 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67dbf7f3e264a4ca9881432090c726a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.79G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f219b15012b4f0ca4eb967097e5b3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/197 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load PRIMERA tokenizer and model\n",
    "model_name = \"allenai/PRIMERA\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "def summarize_text(text, max_length=150, min_length=50):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=4096, truncation=True)\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_length=max_length, \n",
    "        min_length=min_length, \n",
    "        length_penalty=2.0, \n",
    "        num_beams=4\n",
    "    )\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample long text\n",
    "text1 = \"\"\"\n",
    "Quantum computing has the potential to revolutionize fields like cryptography, optimization, \n",
    "and materials science. Unlike classical computers, which use bits as the smallest unit of data, \n",
    "quantum computers use qubits, which can exist in superposition states. This property enables \n",
    "quantum computers to perform certain calculations exponentially faster than their classical \n",
    "counterparts. However, challenges like error rates and qubit stability must be addressed for \n",
    "practical large-scale quantum computing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nevetheless, large-scale quantum computing is still a distant dream for most researchers, who are still working to overcome the technical challenges that must be overcome to realize the full potential of quantum computing.​​​​​​​​​ ​​​­​​​​​​ ​​​​​ ​​​​​​ ​​​​​­​​​­ ​​ ​ ​​­​ ​­­­ ​ ​ ​​​ ​­ ​​​­­​​ Â ​​ « ​​quantum computing has the potential to revolutionize fields like cryptography, optimization, �and materials science.​ ​Â ​ ​­​​​­​­­​​ ​Â​​Â ​​​Â ​­​​­ ​­\n"
     ]
    }
   ],
   "source": [
    "# Generate summary\n",
    "primera_summary = summarize_text(text1)\n",
    "print(primera_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"\n",
    " Since 1980, Quantum Computing has garnered significant interest owing to its substantial\n",
    " benefits in addressing complex computational challenges, including integer factorization,\n",
    " database searching, and machine learning. In 1997, Daniel R. Simon presented persuasive\n",
    " data indicating that the quantum model may possess far greater complexity-theoretic capacity\n",
    " than the probabilistic Turing machine. Nonetheless, the delineation between classical\n",
    " computing and quantum computing remains a compelling inquiry. Despite numerous\n",
    " suggested quantum algorithms demonstrating exponential speedups compared to classical\n",
    " algorithms, is there a method to enhance classical algorithms to achieve comparable\n",
    " complexity to their quantum equivalents? [1].\n",
    " The field of Machine Learning, a fundamental aspect of artificial intelligence, has undergone\n",
    " significant progress in recent decades. Support vector machines (SVMs) and Neural networks\n",
    " (NNs) have emerged as a potent and extensively utilized method for classification problems\n",
    " among many machines learning techniques, owing to their capacity to manage high\n",
    "dimensional data and deliver strong results. Support Vector Machines (SVMs) operate by\n",
    " identifying the best hyperplane that maximizes the margin between data points of disparate\n",
    " classes, hence maintaining a sharp separation between categories. Notwithstanding their\n",
    " effectiveness, classical SVMs face considerable obstacles as data volumes escalate and issues\n",
    " grow more complex. The computing demands for training SVMs increase significantly with\n",
    " the quantity of the dataset and the complexity of the feature space. This inefficiency stems\n",
    " from the necessity to resolve a difficult quadratic programming problem, which becomes\n",
    " computationally demanding for extensive datasets.\n",
    " Quantum computing offers an innovative resolution to these issues by utilizing the laws of\n",
    " quantum mechanics fundamentally novel manners. Unlike classical bits which represent data\n",
    " as 0 or 1, quantum bits(qubits) can be in superpositions of both states simultaneously,\n",
    " allowing them to do many calculations concurrently. This intrinsic parallelism provides the\n",
    " possibility of exponential acceleration in specific computational processes, particularly those\n",
    " related to machine learning techniques. Moreover, quantum entanglement and interference\n",
    "are supplementary quantum phenomena that can be utilized to improve computer\n",
    " performance. Entanglement permits entangled qubits to instantaneously affect one another,\n",
    " irrespective of the distance between them, facilitating accelerated information processing and\n",
    " transfer. Quantum interference enables quantum algorithms to enhance accurate solutions\n",
    " while negating wrong ones, thus improving the accuracy and efficiency of calculations.\n",
    " Integrating quantum concepts into support vector machines creates Quantum Support Vector\n",
    " Machines (QSVMs), which may far surpass their conventional equivalents. Quantum Support\n",
    " Vector Machines (QSVMs) utilize quantum methods, such the Harrow-Hassidim-Lloyd\n",
    " (HHL) algorithm, to address the fundamental optimization challenges in Support Vector\n",
    " Machines (SVMs) with more efficiency [2].\n",
    " Within the field of machine learning, a classifier refers to as a mathematical model or\n",
    " computational technique that processes input feature vectors and assigns them specific\n",
    " categories or ‘labels. For instance, the attributes extracted from an image, can be used to\n",
    " determine the image as \"depicts an apple \" or \"does not depict an apple.\" Such a classifier can\n",
    " be formulated, by a function �: � → �, which maps an input space � to a set of possible\n",
    " labels �. The function is typically parametrized by �, and training the classifier involves\n",
    " adjusting these parameters using a set of input- label pairs to create a model\n",
    " �( �; �), � ∈ � that can generalize to classify unseen data. A common approach is to utilize\n",
    " an ensemble of models �(�; 𝜃), where � = 1, ..., � , in order to generate a collective\n",
    " prediction that outperforms any single classifier.\n",
    " In the nascent field of quantum machine learning, several quantum classification algorithms\n",
    " have been suggested and illustrate the methodology for training and utilizing classification\n",
    " models on a quantum computer.\n",
    " The method of integrating quantum classifiers into a grouped architecture that leverages the\n",
    " advantages of quantum computing remains an unresolved issue, and this study is an initial\n",
    " effort to address this inquiry. We will concentrate on a specific sort of quantum classifier,\n",
    " specifically a model in which a set of parameters � can be represented by an n-qubit state\n",
    " |�〉, and the classification outcome is encoded in a distinct register of qubits. This structure\n",
    " enables the creation of a 'superposition of quantum models' ∑�|�〉 and facilitates their parallel\n",
    " evaluation. A state preparation strategy can be employed to evaluate each classifier, thus\n",
    " forming the ensemble. This enables the immediate assessment of exponentially vast quantum\n",
    " ensembles of quantum classifiers[3]. There are several quantum simulators that provide the\n",
    " operations of quantum machine learning, i.e., Google’s Cirq, Righetti’s Pennylane, IBM’s\n",
    " Qiskit, and so on. These platforms serve as an essential tool for simulating quantum\n",
    " algorithms and implementing quantum machine learning algorithms. This paper is structured\n",
    " into several sections. Literature review of the existing studies is explained in next section\n",
    " followed by methodology and result section, conclusion summarizes the findings and\n",
    " emphasise the contribution of the proposed Quantum support vector neural network to the\n",
    " field of quantum enhancing machine learning.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 1083 to 1536 to be a multiple of `config.attention_window`: 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "汼 In the field of machine learning, a classifier refers to as a mathematical model or a computer model, a model that can be used to compute the output of a machine learning algorithm. . The field of Machine Learning, a fundamental aspect of artificial intelligence, has undergone experiencing significant progress in recent decades. Support vector machines (SVMs) and Neural networks                 (NNs) have emerged as a potent and extensively utilized method for classification problems                 among many machines learning techniques, owing to their capacity to manage high                dimensional data and deliver strong results. Support Vector Machines (SvMs) operate by                 identifying the best hyperplane that maximizes the margin between data points of disparate                 classes, hence maintaining a sharp separation between categories\n"
     ]
    }
   ],
   "source": [
    "# Generate summary\n",
    "primera_summary = summarize_text(text2)\n",
    "print(primera_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "1. facebook/bart-large-cnn summarizer\n",
    "\n",
    "    *   It is summarizing Input text by using first few lines of input text. \n",
    "    \n",
    "    *   Not Actually grabbing the gist of the input text.\n",
    "\n",
    "2. google/pegasus-xsum summarizer\n",
    "\n",
    "    *   It is providing title to the input text as a summary of output.\n",
    "    *   It is capturing actual gist of the given input very accurately.\n",
    "\n",
    "3. Python library sumy\n",
    "\n",
    "    *   It only concatenates different sentences provided in the input text\n",
    "    *   Not able to capture the gist of the input text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
